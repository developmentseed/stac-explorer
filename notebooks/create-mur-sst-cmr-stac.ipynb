{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5607aa-2e4e-4f14-a56b-40ec6cdb9c50",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "title: Create STAC metadata for MUR SST \n",
    "description: Tutorial for creating STAC metadata for a collection in CMR\n",
    "author: Aimee Barciauskas\n",
    "date: January 18, 2024\n",
    "execute:\n",
    "  freeze: true\n",
    "  cache: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b260955",
   "metadata": {},
   "source": [
    "## Run this notebook\n",
    "\n",
    "You can launch this notebook in VEDA JupyterHub by clicking the link below.\n",
    "\n",
    "[Launch in VEDA JupyterHub (requires access)](https://nasa-veda.2i2c.cloud/hub/user-redirect/git-pull?repo=https://github.com/NASA-IMPACT/veda-docs&urlpath=lab/tree/veda-docs/notebooks/veda-operations/publish-cmip6-kerchunk-stac.ipynb&branch=main) \n",
    "\n",
    "<details><summary>Learn more</summary>\n",
    "    \n",
    "### Inside the Hub\n",
    "\n",
    "This notebook was written on a VEDA JupyterHub instance\n",
    "\n",
    "See (VEDA Analytics JupyterHub Access)[https://nasa-impact.github.io/veda-docs/veda-jh-access.html] for information about how to gain access.\n",
    "\n",
    "### Outside the Hub\n",
    "\n",
    "You are welcome to run this anywhere you like (Note: alternatively you can run this on https://daskhub.veda.smce.nasa.gov/, MAAP, locally, ...), just make sure that the data is accessible, or get in contact with the VEDA team to enable access.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279606ac-6886-4cf0-8248-e26a84694a72",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "This notebook creates STAC collection metadata for the [MUR SST](https://search.earthdata.nasa.gov/search/granules?p=C1996881146-POCLOUD) dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca29984-ac2b-4f41-8ae2-d8d57c8968ef",
   "metadata": {},
   "source": [
    "## Step 1: Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce71f2c2-0b47-4be5-9bad-d51a0ce56015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install xstac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e37cc9-6022-46c2-aa20-4bb87dd502f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pystac\n",
    "import requests\n",
    "import s3fs\n",
    "import xstac\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256d2e4-6ff0-461d-a847-794aae86e444",
   "metadata": {},
   "source": [
    "## Step 2: Get Collection metadata from CMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d11fbe9-f562-481c-8648-f43b17896665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EARTHDATA_USERNAME and EARTHDATA_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\n",
      "No .netrc found in /home/jovyan\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Earthdata Login username:  aimeeb\n",
      "Enter your Earthdata password:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're now authenticated with NASA Earthdata Login\n",
      "Using token with expiration date: 03/12/2024\n",
      "Using user provided credentials for EDL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<earthaccess.auth.Auth at 0x7f8a83a3b280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e24555-e74f-491a-a159-d3b26174a24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "short_name = 'MUR-JPL-L4-GLOB-v4.1'\n",
    "collection_query = earthaccess.collection_query()\n",
    "r = collection_query.short_name(short_name)\n",
    "cmr_collection = r.get(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65d201-50b4-477f-8a7f-4cf85bf66ceb",
   "metadata": {},
   "source": [
    "Pick out one granule to open for data cube dimensions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa6ab048-e747-46dc-8c55-b9d3aaa06a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granules found: 7902\n"
     ]
    }
   ],
   "source": [
    "first_result = earthaccess.search_data(\n",
    "    short_name='MUR-JPL-L4-GLOB-v4.1',\n",
    "    cloud_hosted=True,\n",
    "    count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5ea85-f5dd-4805-a6fe-0295724d691e",
   "metadata": {},
   "source": [
    "### Sidebar: S3 vs HTTPS access\n",
    "\n",
    "Right now, earthaccess only supports `open` over https. Below, we see that open the dataset with direct S3 access is many times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a643e4-fde7-4cf1-a0d1-52fca2b9a616",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Opening 1 granules, approx size: 0.0 GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cda8a183e204569b55af97cb023e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59c356499cf426295e9072ad60cfbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004e660b3d1a43c4902f8be6b0ded4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = earthaccess.open(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8c791e-a360-420b-9a4f-d285994c846a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 s, sys: 121 ms, total: 2.58 s\n",
      "Wall time: 5.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_https = xr.open_mfdataset(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06221618-a2a7-4e8e-bfe0-e836e6ad1323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_link = first_result[0].data_links(access='direct')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9405cbcc-e001-4c75-93be-0b004ad51678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 32.5 ms, total: 241 ms\n",
      "Wall time: 451 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fs = s3fs.S3FileSystem(anon=False)\n",
    "# Open the dataset using xarray\n",
    "# The 'chunks' parameter enables Dask for lazy loading\n",
    "ds_s3 = xr.open_dataset(fs.open(s3_link), engine='h5netcdf', chunks={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4449a055-779e-4024-a871-ddf107cb27d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Generate STAC metadata\n",
    "\n",
    "The spatial and temporal extents are extracted from the CMR collection metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47cba6c5-2d6c-4829-8b49-ada67e6b5522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_extent = cmr_collection['umm']['SpatialExtent']\n",
    "bounding_rectangle = spatial_extent['HorizontalSpatialDomain']['Geometry']['BoundingRectangles'][0]\n",
    "extent_list = [\n",
    "    bounding_rectangle[\"WestBoundingCoordinate\"],\n",
    "    bounding_rectangle[\"SouthBoundingCoordinate\"],   \n",
    "    bounding_rectangle[\"EastBoundingCoordinate\"],\n",
    "    bounding_rectangle[\"NorthBoundingCoordinate\"],    \n",
    "]\n",
    "spatial_extent = list(map(int, extent_list))\n",
    "\n",
    "temporal_extent = cmr_collection['umm']['TemporalExtents'][0]['RangeDateTimes'][0]\n",
    "start = temporal_extent['BeginningDateTime']\n",
    "end = temporal_extent.get('EndingDateTime', None)\n",
    "\n",
    "extent = pystac.Extent(\n",
    "    spatial=pystac.SpatialExtent(bboxes=[spatial_extent]),\n",
    "    temporal=pystac.TemporalExtent([[pd.to_datetime(start), pd.to_datetime(end)]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3351996d-f124-410d-a6a2-55abcdb2aecb",
   "metadata": {},
   "source": [
    "Add the provider information from CMR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7dad951-557c-4121-b4fa-4c51ab4723a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmr_roles_to_pystac_roles = {\n",
    "    'PROCESSOR': pystac.ProviderRole.PROCESSOR,\n",
    "    'DISTRIBUTOR': pystac.ProviderRole.HOST\n",
    "}\n",
    "def create_providers_from_data_centers(data_centers):\n",
    "    providers = []\n",
    "\n",
    "    for center in data_centers:\n",
    "        # Extracting necessary information from each data center\n",
    "        short_name = center.get(\"ShortName\", \"\")\n",
    "        long_name = center.get(\"LongName\", \"\")\n",
    "        roles = []\n",
    "        for role in center.get(\"Roles\", []):\n",
    "            if role in cmr_roles_to_pystac_roles:\n",
    "                roles.append(cmr_roles_to_pystac_roles[role])\n",
    "        url = next((url_info[\"URL\"] for url_info in center.get(\"ContactInformation\", {}).get(\"RelatedUrls\", []) \n",
    "                    if url_info.get(\"URLContentType\") == \"DataCenterURL\"), None)\n",
    "\n",
    "        # Creating a PySTAC Provider object\n",
    "        provider = pystac.Provider(name=short_name, description=long_name, roles=roles, url=url)\n",
    "        providers.append(provider)\n",
    "\n",
    "    return providers\n",
    "\n",
    "data_centers = cmr_collection['umm']['DataCenters']\n",
    "providers = create_providers_from_data_centers(data_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bb7f1-4eb3-4d6d-9fd2-f3800c2cf57e",
   "metadata": {},
   "source": [
    "Put it all together to intialize a `pystac.Collection` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a36bb5c-1425-4818-8d05-4c29bcd35590",
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = short_name.replace('.', '_')\n",
    "description = cmr_collection['umm']['Abstract']\n",
    "concept_id = cmr_collection['meta']['concept-id']\n",
    "collection = pystac.Collection(\n",
    "    id=_id,\n",
    "    extent=extent,\n",
    "    description=cmr_collection['umm']['Abstract'],\n",
    "    providers=providers,\n",
    "    stac_extensions=['https://stac-extensions.github.io/datacube/v2.0.0/schema.json'],\n",
    "    license=\"CC0-1.0\",\n",
    "    extra_fields={'collection_concept_id': concept_id}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f31a852-c727-4a46-97c8-44de1e965345",
   "metadata": {},
   "source": [
    "That collection instance is used by `xstac` to generate additional metadata, specifically for the [`datacube extension`](https://github.com/stac-extensions/datacube) information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d66cd1e6-9c29-429d-b569-be5f6c69d6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://schemas.stacspec.org/v1.0.0/collection-spec/json-schema/collection.json',\n",
       " 'https://stac-extensions.github.io/datacube/v2.0.0/schema.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_template = collection.to_dict()\n",
    "\n",
    "# see https://github.com/stac-utils/xstac/issues/30\n",
    "for k, v in ds_s3.variables.items():\n",
    "    attrs = {name: xr.backends.zarr.encode_zarr_attr_value(value) for name, value in v.attrs.items()}\n",
    "    ds_s3[k].attrs = attrs\n",
    "        \n",
    "collection = xstac.xarray_to_stac(\n",
    "    ds_s3,\n",
    "    collection_template,\n",
    "    temporal_dimension='time',\n",
    "    x_dimension=\"lon\",\n",
    "    y_dimension=\"lat\",\n",
    "    # TODO: get this from attributes if possible\n",
    "    reference_system=\"4326\",\n",
    "    validate=False\n",
    ")\n",
    "# It should validate, but it doesn't :(\n",
    "# TODO: investigate why this is not validating.\n",
    "# TypeError: Object of type int16 is not JSON serializable\n",
    "collection.validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce29f9-c3f4-432c-9cd2-d659ca0e63e4",
   "metadata": {},
   "source": [
    "Set the second value for the time extent to `None` since the dataset is ongoing. Otherwise the extent is just the extent of the first file in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84c1d969-4c8c-4b33-a4da-5144fc73115c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection.to_dict()['cube:dimensions']['time']['extent'][1] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f407c4-0356-45f5-aac0-c97e62e49e77",
   "metadata": {},
   "source": [
    "Add [renders](https://github.com/stac-extensions/render) extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f0bc3c-1c23-4b3f-8f70-5b8bc40d3115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection.extra_fields['renders'] = {\n",
    "    \"analysed_sst\": {\n",
    "      \"title\": \"Renders configuration for sea surface temperature\",\n",
    "      \"resampling\": \"average\",\n",
    "      \"colormap_name\": \"ocean\",\n",
    "      \"rescale\": [[271,305]]\n",
    "    }\n",
    "}\n",
    "collection.to_dict()['cube:variables']['analysed_sst']['renders'] = \"analysed_sst\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8156274-d9c5-47c9-a869-e55f214d8a06",
   "metadata": {},
   "source": [
    "## Step 4: Write to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42d3023b-b551-43c1-9984-22553eb41fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{collection.id}.stac.json\", \"w+\") as f:\n",
    "    f.write(json.dumps(collection.to_dict()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
